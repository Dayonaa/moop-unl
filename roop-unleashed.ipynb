{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9BdiCppV6AS"
   },
   "source": [
    "# Colab for roop-unleashed - Gradio version\n",
    "https://codeberg.org/roop-unleashed/roop-unleashed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CanIXgLJgaOj"
   },
   "source": [
    "Install CUDA 12.6 & CUDNN on Google Cloud Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96GE4UgYg3Ej"
   },
   "outputs": [],
   "source": [
    "!apt-get -y update\n",
    "!apt-get -y install cuda-toolkit-12-6\n",
    "!apt-get -y install cudnn9-cuda-12\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] += \":\" + \"/usr/local/cuda-12/lib64\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] += \":\" + \"/usr/local/cuda-12.6/lib64\"\n",
    "\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZYRNb0AWLLW"
   },
   "source": [
    "Installing & preparing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1yPuhdySqCq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] += \":\" + \"/usr/local/cuda-12/lib64\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] += \":\" + \"/usr/local/cuda-12.6/lib64\"\n",
    "!nvcc --version\n",
    "!git clone https://github.com/Dayonaa/moop-unl.git\n",
    "%cd moop-unl\n",
    "!mv config_colab.yaml config.yaml\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Download Models\n",
    "import os\n",
    "\n",
    "# Folder model utama\n",
    "base_dir = \"models\"\n",
    "\n",
    "# Daftar URL + folder tujuan\n",
    "files = [\n",
    "    # root models\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/inswapper_128.onnx\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/reswapper_128.onnx\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/reswapper_256.onnx\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/GFPGANv1.4.onnx\", \"\"),\n",
    "    (\"https://github.com/csxmli2016/DMDNet/releases/download/v1/DMDNet.pth\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/GPEN-BFR-512.onnx\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/restoreformer_plus_plus.onnx\", \"\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/xseg.onnx\", \"\"),\n",
    "\n",
    "    # CLIP\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/rd64-uni-refined.pth\", \"CLIP\"),\n",
    "\n",
    "    # buffalo_l\n",
    "    (\"https://huggingface.co/halllooo/buffalo_l/resolve/main/1k3d68.onnx\", \"buffalo_l\"),\n",
    "    (\"https://huggingface.co/halllooo/buffalo_l/resolve/main/2d106det.onnx\", \"buffalo_l\"),\n",
    "    (\"https://huggingface.co/halllooo/buffalo_l/resolve/main/det_10g.onnx\", \"buffalo_l\"),\n",
    "    (\"https://huggingface.co/halllooo/buffalo_l/resolve/main/genderage.onnx\", \"buffalo_l\"),\n",
    "    (\"https://huggingface.co/halllooo/buffalo_l/resolve/main/w600k_r50.onnx\", \"buffalo_l\"),\n",
    "\n",
    "    # CodeFormer\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/CodeFormerv0.1.onnx\", \"CodeFormer\"),\n",
    "\n",
    "    # Frame\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/deoldify_artistic.onnx\", \"Frame\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/deoldify_stable.onnx\", \"Frame\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/isnet-general-use.onnx\", \"Frame\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/real_esrgan_x4.onnx\", \"Frame\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/real_esrgan_x2.onnx\", \"Frame\"),\n",
    "    (\"https://huggingface.co/countfloyd/deepfake/resolve/main/lsdir_x4.onnx\", \"Frame\"),\n",
    "]\n",
    "\n",
    "# Download memakai wget\n",
    "for url, folder in files:\n",
    "    target_folder = os.path.join(base_dir, folder)\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    filepath = os.path.join(target_folder, filename)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"[SKIP] Sudah ada: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[DOWNLOAD] {filename}\")\n",
    "    !wget -O \"{filepath}\" \"{url}\"\n",
    "\n",
    "print(\"\\n=== DONE ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_4JQiSlV9Fi"
   },
   "source": [
    "Running roop-unleashed with default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Is6U2huqSzLE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA device is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdQ1VHdI8lCf"
   },
   "source": [
    "### Download generated images folder\n",
    "(only needed if you want to zip the generated output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "oYjWveAmw10X",
    "outputId": "5b4c3650-f951-434a-c650-5525a8a70c1e"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_789eab11-93d2-4880-adf3-6aceee0cc5f9\", \"fake_output.zip.zip\", 80125)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "def zip_directory(directory_path, zip_path):\n",
    "    shutil.make_archive(zip_path, \"zip\", directory_path)\n",
    "\n",
    "\n",
    "# Set the directory path you want to download\n",
    "directory_path = \"/content/roop-unleashed/output\"\n",
    "\n",
    "# Set the zip file name\n",
    "zip_filename = \"fake_output.zip\"\n",
    "\n",
    "# Zip the directory\n",
    "zip_directory(directory_path, zip_filename)\n",
    "\n",
    "# Download the zip file\n",
    "files.download(zip_filename + \".zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UdQ1VHdI8lCf"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
